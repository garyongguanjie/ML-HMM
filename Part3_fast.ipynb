{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hmm:\n",
    "    def __init__(self,file,k=3):\n",
    "        self.words = None #set of unique words\n",
    "        self.tag_word_count = None # dict((tag,word),count)\n",
    "        self.transmissions = None # dict((tag_u,tag_v),count)\n",
    "        self.count = None # dict(tag,count)\n",
    "        self.read_file(file,k)\n",
    "        self.tags = set(self.count.keys())\n",
    "        \n",
    "        self.word_ls = tuple(self.words)#tuple cause immutable\n",
    "        self._tag_ls = tuple(self.tags)\n",
    "        #move #START# to first row and #END# to last row\n",
    "        ls = list(self._tag_ls)\n",
    "        ls.remove('#START#')\n",
    "        ls.remove('#END#')\n",
    "        ls.insert(0,'#START#')\n",
    "        ls.append('#END#')\n",
    "        self.tag_ls = tuple(ls)\n",
    "        \n",
    "        self.make_matrix()\n",
    "    \n",
    "    def make_matrix(self):\n",
    "        tag_length = len(self.tag_ls)\n",
    "        transition_matrix = np.zeros((tag_length,tag_length))\n",
    "        \n",
    "        for i in range(tag_length):\n",
    "            for j in range(tag_length):\n",
    "                tag_u = self.tag_ls[i]\n",
    "                tag_v = self.tag_ls[j]\n",
    "                transition_matrix[i][j] = self.transmissions[(tag_u,tag_v)]/self.count[tag_u]\n",
    "        self.transition_matrix = pd.DataFrame(transition_matrix,index=self.tag_ls,columns=self.tag_ls)\n",
    "        \n",
    "        word_length = len(self.word_ls)\n",
    "        em_matrix = np.zeros((tag_length,word_length))\n",
    "        for i in range(tag_length):\n",
    "            for j in range(word_length):\n",
    "                tag = self.tag_ls[i]\n",
    "                word = self.word_ls[j]\n",
    "                em_matrix[i][j] = self.tag_word_count[(tag,word)]/self.count[tag]\n",
    "        self.em_matrix = pd.DataFrame(em_matrix,index=self.tag_ls,columns=self.word_ls)\n",
    "        pass\n",
    "    \n",
    "    def read_file(self,file,k):\n",
    "        from collections import defaultdict\n",
    "        seq = ['#START#']\n",
    "        f = open(file,'r',encoding='UTF-8')\n",
    "        tag_word_ls = []\n",
    "        word_count = defaultdict(int)\n",
    "        for line in f:\n",
    "            split = line.split(' ')\n",
    "            if len(split)<2:\n",
    "                #this is a line break\n",
    "                seq.append('#END#')\n",
    "                seq.append('#START#')\n",
    "                continue\n",
    "            word,tag = split\n",
    "            word = word.strip()\n",
    "            tag = tag.strip()\n",
    "            tag_word_ls.append([tag,word])\n",
    "            word_count[word]+=1\n",
    "            seq.append(tag)\n",
    "        f.close()\n",
    "        \n",
    "        #Emissions\n",
    "        for i in range(len(tag_word_ls)):\n",
    "            tag,word = tag_word_ls[i]\n",
    "            if word_count[word]<k:\n",
    "                tag_word_ls[i] = [tag,'#UNK#']\n",
    "        tag_word_count = defaultdict(int)\n",
    "        \n",
    "        words = []\n",
    "        for tag,word in tag_word_ls:\n",
    "            tag_word_count[tag,word]+=1\n",
    "            words.append(word)\n",
    "        self.words = set(words)\n",
    "        self.tag_word_count= tag_word_count\n",
    "        \n",
    "        #Transistions\n",
    "        del seq[-1] #delete last item from the list\n",
    "         #print(seq)\n",
    "        trans_dict = defaultdict(int)\n",
    "        count_u = defaultdict(int)\n",
    "        for i in range(len(seq)-1):\n",
    "            tag_u = seq[i]\n",
    "            count_u[tag_u] += 1 # need to count #END# too\n",
    "            if tag_u == \"#END#\":\n",
    "                continue\n",
    "            #if u is not #END# we count the transmission \n",
    "            tag_v = seq[i+1]\n",
    "            if (tag_u ==\"#START#\" and tag_v == \"#END#\"):\n",
    "                #check for empty blank lines at the end and dont count them\n",
    "                print('these are blank lines')\n",
    "                count_u[\"#START#\"] -= 1 #remove additional start\n",
    "                break\n",
    "            trans_dict[(tag_u,tag_v)] += 1\n",
    "        self.transmissions = trans_dict\n",
    "        self.count = count_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN = Hmm('./EN/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3120392091152815"
      ]
     },
     "execution_count": 930,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EN.em_matrix.loc['O','.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6480490669450607"
      ]
     },
     "execution_count": 931,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EN.transition_matrix.loc['#START#','B-NP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(m):\n",
    "    m = np.clip(m, 1e-32, None)\n",
    "    x = np.log(m)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertebi(word_arr,Hmm):\n",
    "    \"\"\"\n",
    "    Followed pseudocode here\n",
    "    https://en.wikipedia.org/wiki/Viterbi_algorithm#Pseudocode\n",
    "    \"\"\"\n",
    "    S = Hmm.tag_ls[1:-1] #set of all possible tags remove #START# and #STOP#\n",
    "    \n",
    "    A = Hmm.transition_matrix.values[1:-1,1:-1] # A(tag_u_vector,tag_v)\n",
    "    B = Hmm.em_matrix[1:-1] # B(tag_u->word)\n",
    "    \n",
    "    T = len(S) # Total number unique tags\n",
    "    N = len(word_arr) # Length of sentence make sure no #START# and #STOP#\n",
    "    \n",
    "    T1 = np.zeros((T,N)) #probability table of most possible path to node i.e. store scores of each node\n",
    "    T2 = np.zeros((T,N)) # Table of paths where the ith row stores highest scoring paths to T1[i,j]\n",
    "    \n",
    "    #Handle first word and base case at the same time\n",
    "    word = word_arr[0]\n",
    "    if word not in Hmm.words:\n",
    "        word = '#UNK#'\n",
    "    T1[:,0] = 1*log(Hmm.transition_matrix.loc['#START#'][1:-1].values*B[word].values)\n",
    "    #Note A is vector operation\n",
    "    # Fill up each column by using previous column\n",
    "    # j is position of word\n",
    "    \n",
    "    for j in range(1,N):\n",
    "        # i is position of tag\n",
    "        #ignore #START# and #END# tag when looping\n",
    "        for i in range(T):\n",
    "            tag = S[i]\n",
    "            #note A(S,tag_u gives a vector)\n",
    "            word = word_arr[j]\n",
    "            if word not in Hmm.words:\n",
    "                word = '#UNK#'\n",
    "            T1[i][j] = np.max(T1[:,j-1]+log(A[:,i]*B.loc[tag,word]))\n",
    "            T2[i][j] = np.argmax(T1[:,j-1]+log(A[:,i]))\n",
    "    #handle last word to #END#\n",
    "    #no emission of #END# \n",
    "#     print(T1)\n",
    "#     print(T2)\n",
    "#     print(T1[:,N-1]*A(S,'#END#'))\n",
    "    \n",
    "    best_row = np.argmax(T1[:,N-1]+log(Hmm.transition_matrix['#END#'].values[1:-1]))\n",
    "    ans=[]\n",
    "    curr_index = best_row\n",
    "    ans.append(S[curr_index])\n",
    "    for j in range(N-1,0,-1):\n",
    "        prev_index = T2[int(curr_index)][j]\n",
    "        ans.append(S[int(prev_index)])\n",
    "        curr_index = prev_index\n",
    "#         print(S[j])\n",
    "    ans = ans[::-1]\n",
    "#     print(T1)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 1021,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"Trump is the best president in the world\".split(' ')\n",
    "len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADVP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP']"
      ]
     },
     "execution_count": 1022,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertebi(word,EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG = ['AL','CN','EN','SG']\n",
    "eval_params = lambda lang: {'devin':f'./{lang}/dev.in','devout':f'./{lang}/dev.p3.out','ground_truth':f'./{lang}/dev.out','trainfile':f'./{lang}/train'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def pred_out(devin,devout,ground_truth,trainfile):\n",
    "    H = Hmm(trainfile)\n",
    "    file_object = open(devin, \"r\",encoding='UTF-8',)\n",
    "    ls=[[]]\n",
    "    index=0\n",
    "    test=[]\n",
    "    for line in file_object:\n",
    "        test.append(line.strip())\n",
    "        if (line.strip()==\"\"):\n",
    "            ls.append([])\n",
    "            index+=1\n",
    "        else:\n",
    "            ls[index].append(line.strip())\n",
    "    ls.pop(-1)\n",
    "    df = pd.DataFrame(test, columns = ['Word'])\n",
    "    \n",
    "    from tqdm.notebook import tqdm\n",
    "    predict=[]\n",
    "    for i in tqdm(ls):\n",
    "        for j in vertebi(i,H):\n",
    "            predict.append(j)\n",
    "        predict.append(\"\")\n",
    "    df['Tag'] = predict\n",
    "    \n",
    "    df.to_csv(devout, sep=\" \", index=False, header=False)\n",
    "    \n",
    "    if os.name == 'nt':#if it is on windows\n",
    "        !python ./EvalScript/evalResult.py {ground_truth} {devout}\n",
    "    else:\n",
    "        !python3 ./EvalScript/evalResult.py {ground_truth} {devout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148928c78fb24764b32cb749a1b31cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1492), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#Entity in gold data: 8408\n",
      "#Entity in prediction: 8498\n",
      "\n",
      "#Correct Entity : 6740\n",
      "Entity  precision: 0.7931\n",
      "Entity  recall: 0.8016\n",
      "Entity  F: 0.7974\n",
      "\n",
      "#Correct Sentiment : 6087\n",
      "Sentiment  precision: 0.7163\n",
      "Sentiment  recall: 0.7240\n",
      "Sentiment  F: 0.7201\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a1f3295468464fba8b18c419467fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=642), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#Entity in gold data: 1478\n",
      "#Entity in prediction: 712\n",
      "\n",
      "#Correct Entity : 307\n",
      "Entity  precision: 0.4312\n",
      "Entity  recall: 0.2077\n",
      "Entity  F: 0.2804\n",
      "\n",
      "#Correct Sentiment : 210\n",
      "Sentiment  precision: 0.2949\n",
      "Sentiment  recall: 0.1421\n",
      "Sentiment  F: 0.1918\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276830e166814877916b0948f40e03f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1094), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#Entity in gold data: 13179\n",
      "#Entity in prediction: 13060\n",
      "\n",
      "#Correct Entity : 11079\n",
      "Entity  precision: 0.8483\n",
      "Entity  recall: 0.8407\n",
      "Entity  F: 0.8445\n",
      "\n",
      "#Correct Sentiment : 10651\n",
      "Sentiment  precision: 0.8155\n",
      "Sentiment  recall: 0.8082\n",
      "Sentiment  F: 0.8118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db45eb251f834b5bb3f76cc818ba0504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3107), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#Entity in gold data: 4537\n",
      "#Entity in prediction: 3008\n",
      "\n",
      "#Correct Entity : 1665\n",
      "Entity  precision: 0.5535\n",
      "Entity  recall: 0.3670\n",
      "Entity  F: 0.4414\n",
      "\n",
      "#Correct Sentiment : 1036\n",
      "Sentiment  precision: 0.3444\n",
      "Sentiment  recall: 0.2283\n",
      "Sentiment  F: 0.2746\n"
     ]
    }
   ],
   "source": [
    "for lang in LANG:\n",
    "    pred_out(**eval_params(lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 1]"
      ]
     },
     "execution_count": 948,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
