{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Emission:\n",
    "    def __init__(self,file,k=3):\n",
    "        self.df = None\n",
    "        self.k = k\n",
    "        self.count_series = None\n",
    "        self.word_ls=None\n",
    "        self.unk_ls=None\n",
    "        self.read_file(file)\n",
    "        pass\n",
    "    def read_file(self,file):\n",
    "        file_object = open(file, \"r\",encoding='UTF-8')\n",
    "        dataset=[]\n",
    "        for line in file_object:\n",
    "            dataset.append(line)\n",
    "        data=[]\n",
    "        for i in range(len(dataset)):\n",
    "            temp = dataset[i].split()\n",
    "            if (len(temp)==2):\n",
    "                data.append(temp)\n",
    "        self.df = self.smoothen(pd.DataFrame(data, columns = ['Word', 'Tag']),self.k)\n",
    "        self.count_series = self.df.groupby(['Word', 'Tag']).size()\n",
    "        tag_count = self.df['Tag'].value_counts()\n",
    "        self.count_series = self.count_series / (pd.Series(self.count_series.index.get_level_values('Tag').tolist(), index=self.count_series.index).apply(lambda x: tag_count[x]))\n",
    "        self.word_ls = self.count_series.index.get_level_values('Word').tolist()\n",
    "        self.unk_ls = self.count_series['#UNK#'].index.tolist()\n",
    "        file_object.close()\n",
    "    \n",
    "    def emission(self,tag,word):\n",
    "        try:\n",
    "            return self.count_series.loc[word,tag]\n",
    "        except:\n",
    "            if word in self.word_ls or tag not in self.unk_ls:\n",
    "                return 0.\n",
    "            return self.count_series.loc['#UNK#',tag]\n",
    "\n",
    "    @staticmethod\n",
    "    def smoothen(df,k):\n",
    "        ls = df['Word'].value_counts()[df['Word'].value_counts()<k].index.tolist()\n",
    "        df.loc[df['Word'].isin(ls), 'Word'] = \"#UNK#\"\n",
    "        return df\n",
    "    def argmax(self,word):\n",
    "        \"\"\"\n",
    "        This part not needed in part 3?\n",
    "        produces the tag with highest probability for the word in the sequence.\n",
    "        \"\"\"\n",
    "        if (word==\"\"):\n",
    "            return (\"\",None)\n",
    "        try:\n",
    "            value = self.count_series.loc[word].idxmax()\n",
    "            probability = self.count_series.loc[word].max()\n",
    "        except:\n",
    "            value = self.count_series.loc[\"#UNK#\"].idxmax()\n",
    "            probability = self.count_series.loc[\"#UNK#\"].max()\n",
    "        return (value, probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "('B-VP', 0.03707354471277586)\n"
     ]
    }
   ],
   "source": [
    "EN_Emission = Emission('./EN/train')\n",
    "print(EN_Emission.emission('B-VP', 'the'))\n",
    "print(EN_Emission.argmax('are'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transmission:    \n",
    "    def __init__(self,file):\n",
    "        self.transmissions = None #dictionary where KEY is a tuple (tag_u,tag_v) where tag_u -> tag_v and VALUE = count\n",
    "        self.count = None #dictionary where KEY is the tag and VALUE = count\n",
    "        self.read_file(file)\n",
    "    def read_file(self,file):\n",
    "        \"\"\"\n",
    "        read training file and returns 2 dictionaries\n",
    "        RETURNS trans_dict,count_u\n",
    "        trans_dict - > dictionary where KEY is a tuple (tag_u,tag_v) where tag_u _> tag_v and VALUE = count\n",
    "        count_u -> KEY is the tag and VALUE = count\n",
    "        \"\"\"\n",
    "        from collections import defaultdict\n",
    "        seq = ['#START#']\n",
    "        f = open(file,'r',encoding='UTF-8')\n",
    "        for line in f:\n",
    "            split = line.split(' ')\n",
    "            if len(split)<2:\n",
    "                #this is a line break\n",
    "                seq.append('#END#')\n",
    "                seq.append('#START#')\n",
    "                continue\n",
    "            word,tag = split\n",
    "            word = word.strip()\n",
    "            tag = tag.strip()\n",
    "            seq.append(tag)\n",
    "        f.close()\n",
    "        del seq[-1] #delete last item from the list\n",
    "#         print(seq)\n",
    "        trans_dict = defaultdict(int)\n",
    "        count_u = defaultdict(int)\n",
    "        for i in range(len(seq)-1):\n",
    "            tag_u = seq[i]\n",
    "            count_u[tag_u] += 1 # need to count #END# too\n",
    "            if tag_u == \"#END#\":\n",
    "                continue\n",
    "            #if u is not #END# we count the transmission \n",
    "            tag_v = seq[i+1]\n",
    "            if (tag_u ==\"#START#\" and tag_v == \"#END#\"):\n",
    "                #check for empty blank lines at the end and dont count them\n",
    "                print('these are blank lines')\n",
    "                count_u[\"#START#\"] -= 1 #remove additional start\n",
    "                break\n",
    "            trans_dict[(tag_u,tag_v)] += 1\n",
    "        self.transmissions = trans_dict\n",
    "        self.count = count_u\n",
    "        return trans_dict,count_u\n",
    "    def transmission_proba(self,tag_u,tag_v):\n",
    "        \"\"\"\n",
    "        Auv = Count(tag_u->tag_v)/Count(tag_u)\n",
    "        \"\"\"\n",
    "        return self.transmissions[(tag_u,tag_v)]/self.count[tag_u]\n",
    "    \n",
    "    def vector_proba(self,ls,tag_v):\n",
    "        #lazy calculation instead of using transistion matrix(in slides)\n",
    "        \"\"\"\n",
    "        Returns vectorized formed when a list of tag_u is given \n",
    "        \"\"\"\n",
    "        ans = []\n",
    "        for word in ls:\n",
    "            ans.append(self.transmission_proba(word,tag_v))\n",
    "        return np.array(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6480490669450607\n",
      "0.00023253355882042067\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "EN_transmission = Transmission('./EN/train')\n",
    "print(EN_transmission.transmission_proba('#START#','B-NP'))\n",
    "print(EN_transmission.transmission_proba('B-NP','#END#'))\n",
    "print(EN_transmission.transmission_proba('#START#','#START#'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertebi(word_arr,Transmission,Emission):\n",
    "    \"\"\"\n",
    "    Followed pseudocode here\n",
    "    https://en.wikipedia.org/wiki/Viterbi_algorithm#Pseudocode\n",
    "    \"\"\"\n",
    "    S = list(Transmission.count.keys()) #set of all possible tags remove #START# and #STOP#\n",
    "    S.remove('#START#')\n",
    "    S.remove('#END#')\n",
    "    A = Transmission.vector_proba # A(tag_u_vector,tag_v)\n",
    "    B = Emission.emission # B(tag_u->word)\n",
    "    T = len(S) # Total number unique tags\n",
    "    N = len(word_arr) # Length of sentence make sure no #START# and #STOP#\n",
    "    \n",
    "    T1 = np.zeros((T,N)) #probability table of most possible path to node i.e. store scores of each node\n",
    "    T2 = np.zeros((T,N)) # Table of paths where the ith row stores highest scoring paths to T1[i,j]\n",
    "    \n",
    "    #Handle first word and base case at the same time\n",
    "    for i in range(T):\n",
    "        T1[i,0] = 1 * Transmission.transmission_proba('#START#',S[i]) * B(S[i],word_arr[0])\n",
    "        T2[i,0] = 0 #Path for first column is set to 0 same for all\n",
    "    #Note A is vector operation\n",
    "    # Fill up each column by using previous column\n",
    "    # j is position of word\n",
    "    for j in range(1,N):\n",
    "        # i is position of tag\n",
    "        #ignore #START# and #END# tag when looping\n",
    "        for i in range(T):\n",
    "            tag = S[i]\n",
    "            #note A(S,tag_u gives a vector)\n",
    "            T1[i][j] = np.max(T1[:,j-1]*A(S,tag)*B(tag,word_arr[j])) \n",
    "            T2[i][j] = np.argmax(T1[:,j-1]*A(S,tag))\n",
    "    #handle last word to #END#\n",
    "    #no emission of #END# \n",
    "#     print(T1)\n",
    "#     print(T2)\n",
    "#     print(T1[:,N-1]*A(S,'#END#'))\n",
    "    best_row = np.argmax(T1[:,N-1]*A(S,'#END#'))\n",
    "    ans=[]\n",
    "    for j in range(1,N):\n",
    "        index = int(T2[best_row][j])\n",
    "#         print(S[j])\n",
    "        ans.append(S[index])\n",
    "    ans.append(S[best_row])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = ['The','dog','is','a','good','boy', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-NP', 'I-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'O']"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%timeit\n",
    "vertebi(word,EN_transmission,EN_Emission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EN_Emission.emission('O',\"Trump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word     Tag   \n",
       "!        O         0.000628\n",
       "#        B-ADJP    0.001713\n",
       "         B-NP      0.000423\n",
       "         I-NP      0.000183\n",
       "         O         0.000042\n",
       "                     ...   \n",
       "young    I-NP      0.000128\n",
       "younger  B-NP      0.000085\n",
       "         I-NP      0.000092\n",
       "your     B-NP      0.000803\n",
       "         I-NP      0.000037\n",
       "Length: 12171, dtype: float64"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EN_Emission.count_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'dog', 'is', 'a', 'good', 'boy', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HBO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>close</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27220</th>\n",
       "      <td>were</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27221</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27222</th>\n",
       "      <td>Congress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27223</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27224</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27225 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word\n",
       "0           HBO\n",
       "1           has\n",
       "2         close\n",
       "3            to\n",
       "4            24\n",
       "...         ...\n",
       "27220      were\n",
       "27221        in\n",
       "27222  Congress\n",
       "27223         .\n",
       "27224          \n",
       "\n",
       "[27225 rows x 1 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_object = open(\"./EN/dev.in\", \"r\")\n",
    "ls=[[]]\n",
    "index=0\n",
    "test=[]\n",
    "for line in file_object:\n",
    "    test.append(line.strip())\n",
    "    if (line.strip()==\"\"):\n",
    "        ls.append([])\n",
    "        index+=1\n",
    "    else:\n",
    "        ls[index].append(line.strip())\n",
    "ls.pop(-1)\n",
    "EN_test_df = pd.DataFrame(test, columns = ['Word'])\n",
    "EN_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-NP',\n",
       " 'I-NP',\n",
       " 'I-NP',\n",
       " 'B-PP',\n",
       " 'B-NP',\n",
       " 'I-NP',\n",
       " 'I-NP',\n",
       " 'B-NP',\n",
       " 'I-NP',\n",
       " 'I-NP',\n",
       " 'O']"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertebi(ls[1],EN_transmission,EN_Emission)\n",
    "# print(len(ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202c8a55ed9745b290f2541470fdf927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1094), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HBO</td>\n",
       "      <td>B-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>has</td>\n",
       "      <td>B-VP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>close</td>\n",
       "      <td>I-VP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>I-VP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>B-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27220</th>\n",
       "      <td>were</td>\n",
       "      <td>B-VP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27221</th>\n",
       "      <td>in</td>\n",
       "      <td>B-PP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27222</th>\n",
       "      <td>Congress</td>\n",
       "      <td>B-NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27223</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27224</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word   Tag\n",
       "0           HBO  B-NP\n",
       "1           has  B-VP\n",
       "2         close  I-VP\n",
       "3            to  I-VP\n",
       "4            24  B-NP\n",
       "...         ...   ...\n",
       "27220      were  B-VP\n",
       "27221        in  B-PP\n",
       "27222  Congress  B-NP\n",
       "27223         .     O\n",
       "27224                \n",
       "\n",
       "[27225 rows x 2 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "predict=[]\n",
    "for i in tqdm(ls):\n",
    "    for j in vertebi(i,EN_transmission,EN_Emission):\n",
    "        predict.append(j)\n",
    "    predict.append(\"\")\n",
    "EN_test_df['Tag'] = predict\n",
    "EN_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_test_df.to_csv(\"./EN/dev.p3.out\", sep=\" \", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#Entity in gold data: 13179\r\n",
      "#Entity in prediction: 13730\r\n",
      "\r\n",
      "#Correct Entity : 10567\r\n",
      "Entity  precision: 0.7696\r\n",
      "Entity  recall: 0.8018\r\n",
      "Entity  F: 0.7854\r\n",
      "\r\n",
      "#Correct Sentiment : 9537\r\n",
      "Sentiment  precision: 0.6946\r\n",
      "Sentiment  recall: 0.7237\r\n",
      "Sentiment  F: 0.7088\r\n"
     ]
    }
   ],
   "source": [
    "!python3 ./EvalScript/evalResult.py ./EN/dev.out ./EN/dev.p3.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
