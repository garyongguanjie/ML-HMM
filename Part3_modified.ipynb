{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Emission:\n",
    "    def __init__(self,file,k=3):\n",
    "        self.df = None\n",
    "        self.k = k\n",
    "        self.count_series = None\n",
    "        self.word_ls=None\n",
    "        self.unk_ls=None\n",
    "        self.dic=None\n",
    "        self.read_file(file)\n",
    "        pass\n",
    "    def read_file(self,file):\n",
    "        file_object = open(file, \"r\",encoding='UTF-8')\n",
    "        dataset=[]\n",
    "        for line in file_object:\n",
    "            dataset.append(line)\n",
    "        data=[]\n",
    "        for i in range(len(dataset)):\n",
    "            temp = dataset[i].split()\n",
    "            if (len(temp)==2):\n",
    "                data.append(temp)\n",
    "        self.df = self.smoothen(pd.DataFrame(data, columns = ['Word', 'Tag']),self.k)\n",
    "        self.count_series = self.df.groupby(['Word', 'Tag']).size()\n",
    "        tag_count = self.df['Tag'].value_counts()\n",
    "        self.count_series = self.count_series / (pd.Series(self.count_series.index.get_level_values('Tag').tolist(), index=self.count_series.index).apply(lambda x: tag_count[x]))\n",
    "        self.word_ls = self.count_series.index.get_level_values('Word').tolist()\n",
    "        self.unk_ls = self.count_series['#UNK#'].index.tolist()\n",
    "        self.dic=self.count_series.to_dict()\n",
    "        file_object.close()\n",
    "    \n",
    "    def emission(self,tag,word):\n",
    "        if (word,tag) in self.dic:\n",
    "            return self.dic[word,tag]\n",
    "        else:\n",
    "            if tag not in self.unk_ls or word in self.word_ls:\n",
    "                return 0.\n",
    "            return self.dic['#UNK#',tag]\n",
    "\n",
    "    @staticmethod\n",
    "    def smoothen(df,k):\n",
    "        ls = df['Word'].value_counts()[df['Word'].value_counts()<k].index.tolist()\n",
    "        df.loc[df['Word'].isin(ls), 'Word'] = \"#UNK#\"\n",
    "        return df\n",
    "    def argmax(self,word):\n",
    "        \"\"\"\n",
    "        This part not needed in part 3?\n",
    "        produces the tag with highest probability for the word in the sequence.\n",
    "        \"\"\"\n",
    "        if (word==\"\"):\n",
    "            return (\"\",None)\n",
    "        try:\n",
    "            value = self.count_series.loc[word].idxmax()\n",
    "            probability = self.count_series.loc[word].max()\n",
    "        except:\n",
    "            value = self.count_series.loc[\"#UNK#\"].idxmax()\n",
    "            probability = self.count_series.loc[\"#UNK#\"].max()\n",
    "        return (value, probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001282262644025572\n"
     ]
    }
   ],
   "source": [
    "EN_Emission = Emission('./EN/train')\n",
    "print(EN_Emission.emission('I-NP', 'Trump'))\n",
    "# print(EN_Emission.argmax('are'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word   Tag        \n",
      "#UNK#  B-ASSIST       0.004994\n",
      "       B-CELLNO       0.003771\n",
      "       B-CITY         0.003160\n",
      "       B-COMMUNITY    0.031778\n",
      "       B-DEVZONE      0.004988\n",
      "                        ...   \n",
      "龙      I-SUBROAD      0.002801\n",
      "       I-TOWN         0.002512\n",
      "龚      B-POI          0.000680\n",
      "       I-POI          0.000035\n",
      "       I-ROAD         0.000066\n",
      "Length: 13781, dtype: float64\n",
      "0.0028011204481792717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['B-ASSIST',\n",
       " 'B-CELLNO',\n",
       " 'B-CITY',\n",
       " 'B-COMMUNITY',\n",
       " 'B-DEVZONE',\n",
       " 'B-DISTRICT',\n",
       " 'B-FLOORNO',\n",
       " 'B-HOUSENO',\n",
       " 'B-PERSON',\n",
       " 'B-POI',\n",
       " 'B-REDUNDANT',\n",
       " 'B-ROAD',\n",
       " 'B-ROADNO',\n",
       " 'B-ROOMNO',\n",
       " 'B-SUBPOI',\n",
       " 'B-SUBROAD',\n",
       " 'B-SUBROADNO',\n",
       " 'B-TOWN',\n",
       " 'I-ASSIST',\n",
       " 'I-CITY',\n",
       " 'I-COMMUNITY',\n",
       " 'I-DEVZONE',\n",
       " 'I-DISTRICT',\n",
       " 'I-FLOORNO',\n",
       " 'I-HOUSENO',\n",
       " 'I-PERSON',\n",
       " 'I-POI',\n",
       " 'I-REDUNDANT',\n",
       " 'I-ROAD',\n",
       " 'I-ROADNO',\n",
       " 'I-ROOMNO',\n",
       " 'I-SUBPOI',\n",
       " 'I-SUBROAD',\n",
       " 'I-SUBROADNO',\n",
       " 'I-TOWN']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL_emission = Emission('./AL/train')\n",
    "print(AL_emission.count_series)\n",
    "print(AL_emission.emission('I-SUBROAD','龙'))\n",
    "AL_emission.unk_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transmission:    \n",
    "    def __init__(self,file):\n",
    "        self.transmissions = None #dictionary where KEY is a tuple (tag_u,tag_v) where tag_u -> tag_v and VALUE = count\n",
    "        self.count = None #dictionary where KEY is the tag and VALUE = count\n",
    "        self.read_file(file)\n",
    "    def read_file(self,file):\n",
    "        \"\"\"\n",
    "        read training file and returns 2 dictionaries\n",
    "        RETURNS trans_dict,count_u\n",
    "        trans_dict - > dictionary where KEY is a tuple (tag_u,tag_v) where tag_u _> tag_v and VALUE = count\n",
    "        count_u -> KEY is the tag and VALUE = count\n",
    "        \"\"\"\n",
    "        from collections import defaultdict\n",
    "        seq = ['#START#']\n",
    "        f = open(file,'r',encoding='UTF-8')\n",
    "        for line in f:\n",
    "            split = line.split(' ')\n",
    "            if len(split)<2:\n",
    "                #this is a line break\n",
    "                seq.append('#END#')\n",
    "                seq.append('#START#')\n",
    "                continue\n",
    "            word,tag = split\n",
    "            word = word.strip()\n",
    "            tag = tag.strip()\n",
    "            seq.append(tag)\n",
    "        f.close()\n",
    "        del seq[-1] #delete last item from the list\n",
    "#         print(seq)\n",
    "        trans_dict = defaultdict(int)\n",
    "        count_u = defaultdict(int)\n",
    "        for i in range(len(seq)-1):\n",
    "            tag_u = seq[i]\n",
    "            count_u[tag_u] += 1 # need to count #END# too\n",
    "            if tag_u == \"#END#\":\n",
    "                continue\n",
    "            #if u is not #END# we count the transmission \n",
    "            tag_v = seq[i+1]\n",
    "            if (tag_u ==\"#START#\" and tag_v == \"#END#\"):\n",
    "                #check for empty blank lines at the end and dont count them\n",
    "                print('these are blank lines')\n",
    "                count_u[\"#START#\"] -= 1 #remove additional start\n",
    "                break\n",
    "            trans_dict[(tag_u,tag_v)] += 1\n",
    "        self.transmissions = trans_dict\n",
    "        self.count = count_u\n",
    "        return trans_dict,count_u\n",
    "    def transmission_proba(self,tag_u,tag_v):\n",
    "        \"\"\"\n",
    "        Auv = Count(tag_u->tag_v)/Count(tag_u)\n",
    "        \"\"\"\n",
    "        return self.transmissions[(tag_u,tag_v)]/self.count[tag_u]\n",
    "    \n",
    "    def vector_proba(self,ls,tag_v):\n",
    "        #lazy calculation instead of using transistion matrix(in slides)\n",
    "        \"\"\"\n",
    "        Returns vectorized formed when a list of tag_u is given \n",
    "        \"\"\"\n",
    "        ans = []\n",
    "        for word in ls:\n",
    "            ans.append(self.transmission_proba(word,tag_v))\n",
    "        return np.array(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018661098786376094\n",
      "0.00023253355882042067\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "EN_transmission = Transmission('./EN/train')\n",
    "print(EN_transmission.transmission_proba('#START#','B-VP'))\n",
    "print(EN_transmission.transmission_proba('B-NP','#END#'))\n",
    "print(EN_transmission.transmission_proba('#START#','#START#'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'#START#': 10448,\n",
       "             'B-DISTRICT': 6856,\n",
       "             'I-DISTRICT': 13364,\n",
       "             'B-POI': 7348,\n",
       "             'I-POI': 28472,\n",
       "             'B-HOUSENO': 3455,\n",
       "             'I-HOUSENO': 3045,\n",
       "             'B-CELLNO': 1326,\n",
       "             'I-CELLNO': 1488,\n",
       "             '#END#': 10447,\n",
       "             'B-CITY': 5697,\n",
       "             'I-CITY': 10430,\n",
       "             'B-ROAD': 6324,\n",
       "             'I-ROAD': 15178,\n",
       "             'B-REDUNDANT': 4137,\n",
       "             'I-REDUNDANT': 3668,\n",
       "             'B-PROV': 4488,\n",
       "             'I-PROV': 8666,\n",
       "             'B-SUBROAD': 387,\n",
       "             'I-SUBROAD': 714,\n",
       "             'B-SUBROADNO': 202,\n",
       "             'I-SUBROADNO': 186,\n",
       "             'B-ROADNO': 5061,\n",
       "             'I-ROADNO': 4666,\n",
       "             'B-SUBPOI': 1650,\n",
       "             'I-SUBPOI': 4557,\n",
       "             'B-TOWN': 4612,\n",
       "             'I-TOWN': 10748,\n",
       "             'B-ROOMNO': 3107,\n",
       "             'B-COMMUNITY': 1479,\n",
       "             'I-COMMUNITY': 3148,\n",
       "             'B-FLOORNO': 1229,\n",
       "             'I-FLOORNO': 1237,\n",
       "             'B-PERSON': 713,\n",
       "             'I-PERSON': 2232,\n",
       "             'I-ROOMNO': 1204,\n",
       "             'B-DEVZONE': 401,\n",
       "             'I-DEVZONE': 1834,\n",
       "             'B-ASSIST': 801,\n",
       "             'I-ASSIST': 741,\n",
       "             'B-COUNTRY': 47,\n",
       "             'I-COUNTRY': 47,\n",
       "             'B-OTHERINFO': 3,\n",
       "             'I-OTHERINFO': 1})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL_transmission = Transmission('./AL/train')\n",
    "print(AL_transmission.transmission_proba('#START#','#START#'))\n",
    "AL_transmission.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertebi(word_arr,Transmission,Emission):\n",
    "    \"\"\"\n",
    "    Followed pseudocode here\n",
    "    https://en.wikipedia.org/wiki/Viterbi_algorithm#Pseudocode\n",
    "    \"\"\"\n",
    "    S = list(Transmission.count.keys()) #set of all possible tags remove #START# and #STOP#\n",
    "    S.remove('#START#')\n",
    "    S.remove('#END#')\n",
    "    A = Transmission.vector_proba # A(tag_u_vector,tag_v)\n",
    "    B = Emission.emission # B(tag_u->word)\n",
    "    T = len(S) # Total number unique tags\n",
    "    N = len(word_arr) # Length of sentence make sure no #START# and #STOP#\n",
    "    \n",
    "    T1 = np.zeros((T,N)) #probability table of most possible path to node i.e. store scores of each node\n",
    "    T2 = np.zeros((T,N)) # Table of paths where the ith row stores highest scoring paths to T1[i,j]\n",
    "    \n",
    "    #Handle first word and base case at the same time\n",
    "    for i in range(T):\n",
    "        T1[i,0] = 1 * Transmission.transmission_proba('#START#',S[i]) * B(S[i],word_arr[0])\n",
    "        T2[i,0] = 0 #Path for first column is set to 0 same for all\n",
    "    #Note A is vector operation\n",
    "    # Fill up each column by using previous column\n",
    "    # j is position of word\n",
    "    for j in range(1,N):\n",
    "        # i is position of tag\n",
    "        #ignore #START# and #END# tag when looping\n",
    "        for i in range(T):\n",
    "            tag = S[i]\n",
    "            #note A(S,tag_u gives a vector)\n",
    "            T1[i][j] = np.max(T1[:,j-1]*A(S,tag)*B(tag,word_arr[j])) \n",
    "            T2[i][j] = np.argmax(T1[:,j-1]*A(S,tag))\n",
    "    #handle last word to #END#\n",
    "    #no emission of #END# \n",
    "#     print(T1[:,N-1]*A(S,'#END#'))\n",
    "    best_row = np.argmax(T1[:,N-1]*A(S,'#END#'))\n",
    "    ans=[]\n",
    "    for j in range(1,N):\n",
    "        index = int(T2[best_row][j])\n",
    "#         print(S[j])\n",
    "        ans.append(S[index])\n",
    "#     print(T1)\n",
    "#     print(T2)\n",
    "    ans.append(S[best_row])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = ['The','dog','is','good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = ['杭','州','市','西','湖','区','古','荡','新','c','西','34','幢','八','单','元','1375']\n",
    "# word1 = ['杭','州','市','西','湖','区']\n",
    "# vertebi(word1,AL_transmission,AL_emission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-NP', 'B-NP', 'B-NP', 'B-NP', 'B-NP', 'B-NP', 'B-NP', 'B-NP']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%timeit\n",
    "word = \"Trump is the best president in the world\".split(' ')\n",
    "vertebi(word,EN_transmission,EN_Emission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EN_Emission.emission('O',\"Trump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word     Tag   \n",
       "!        O         0.000628\n",
       "#        B-ADJP    0.001713\n",
       "         B-NP      0.000423\n",
       "         I-NP      0.000183\n",
       "         O         0.000042\n",
       "                     ...   \n",
       "young    I-NP      0.000128\n",
       "younger  B-NP      0.000085\n",
       "         I-NP      0.000092\n",
       "your     B-NP      0.000803\n",
       "         I-NP      0.000037\n",
       "Length: 12171, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EN_Emission.count_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Trump', 'is', 'the', 'best', 'president', 'in', 'the', 'world']\n"
     ]
    }
   ],
   "source": [
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG = ['AL','CN','EN','SG']\n",
    "eval_params = lambda lang: {'devin':f'./{lang}/dev.in','devout':f'./{lang}/dev.p3.out','ground_truth':f'./{lang}/dev.out','trainfile':f'./{lang}/train'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def pred_out(devin,devout,ground_truth,trainfile):\n",
    "    Em = Emission(trainfile)\n",
    "    Trans = Transmission(trainfile)\n",
    "    \n",
    "    \n",
    "    file_object = open(devin, \"r\",encoding='UTF-8',)\n",
    "    ls=[[]]\n",
    "    index=0\n",
    "    test=[]\n",
    "    for line in file_object:\n",
    "        test.append(line.strip())\n",
    "        if (line.strip()==\"\"):\n",
    "            ls.append([])\n",
    "            index+=1\n",
    "        else:\n",
    "            ls[index].append(line.strip())\n",
    "    ls.pop(-1)\n",
    "    df = pd.DataFrame(test, columns = ['Word'])\n",
    "    \n",
    "    from tqdm.notebook import tqdm\n",
    "    predict=[]\n",
    "    for i in tqdm(ls):\n",
    "        for j in vertebi(i,Trans,Em):\n",
    "            predict.append(j)\n",
    "        predict.append(\"\")\n",
    "    df['Tag'] = predict\n",
    "    \n",
    "    df.to_csv(devout, sep=\" \", index=False, header=False)\n",
    "    \n",
    "    if os.name == 'nt':#if it is on windows\n",
    "        !python ./EvalScript/evalResult.py {ground_truth} {devout}\n",
    "    else:\n",
    "        !python3 ./EvalScript/evalResult.py {ground_truth} {devout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141df20f37154cbc9e4486c99e6da014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1492), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#Entity in gold data: 8408\n",
      "#Entity in prediction: 17746\n",
      "\n",
      "#Correct Entity : 2706\n",
      "Entity  precision: 0.1525\n",
      "Entity  recall: 0.3218\n",
      "Entity  F: 0.2069\n",
      "\n",
      "#Correct Sentiment : 1634\n",
      "Sentiment  precision: 0.0921\n",
      "Sentiment  recall: 0.1943\n",
      "Sentiment  F: 0.1250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca124e9de6d4f44be0484a0c28c6d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=642), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#Entity in gold data: 1478\n",
      "#Entity in prediction: 886\n",
      "\n",
      "#Correct Entity : 175\n",
      "Entity  precision: 0.1975\n",
      "Entity  recall: 0.1184\n",
      "Entity  F: 0.1481\n",
      "\n",
      "#Correct Sentiment : 119\n",
      "Sentiment  precision: 0.1343\n",
      "Sentiment  recall: 0.0805\n",
      "Sentiment  F: 0.1007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a6cc2c3b664495960406e71f0ae70a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1094), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#Entity in gold data: 13179\n",
      "#Entity in prediction: 13730\n",
      "\n",
      "#Correct Entity : 10567\n",
      "Entity  precision: 0.7696\n",
      "Entity  recall: 0.8018\n",
      "Entity  F: 0.7854\n",
      "\n",
      "#Correct Sentiment : 9537\n",
      "Sentiment  precision: 0.6946\n",
      "Sentiment  recall: 0.7237\n",
      "Sentiment  F: 0.7088\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da17122ffd34c4288d4637000e85bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3107), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for lang in LANG:\n",
    "    pred_out(**eval_params(lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_out(**eval_params('AL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = open(\"./EN/dev.in\", \"r\")\n",
    "ls=[[]]\n",
    "index=0\n",
    "test=[]\n",
    "for line in file_object:\n",
    "    test.append(line.strip())\n",
    "    if (line.strip()==\"\"):\n",
    "        ls.append([])\n",
    "        index+=1\n",
    "    else:\n",
    "        ls[index].append(line.strip())\n",
    "ls.pop(-1)\n",
    "EN_test_df = pd.DataFrame(test, columns = ['Word'])\n",
    "EN_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertebi(ls[1],EN_transmission,EN_Emission)\n",
    "# print(len(ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "predict=[]\n",
    "for i in tqdm(ls):\n",
    "    for j in vertebi(i,EN_transmission,EN_Emission):\n",
    "        predict.append(j)\n",
    "    predict.append(\"\")\n",
    "EN_test_df['Tag'] = predict\n",
    "EN_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_test_df.to_csv(\"./EN/dev.p3.out\", sep=\" \", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./EvalScript/evalResult.py ./EN/dev.out ./EN/dev.p3.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
