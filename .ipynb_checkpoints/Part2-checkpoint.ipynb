{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x8f in position 2: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a1850283929c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mfile_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_object\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x8f in position 2: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data_ls = []\n",
    "name=['EN','AL','CN','SG']\n",
    "\n",
    "for i in name:\n",
    "    file = \"./\"+i+\"/train\"\n",
    "    file_object = open(file, \"r\",encoding)\n",
    "    dataset=[]\n",
    "    for line in file_object:\n",
    "        dataset.append(line)\n",
    "    data=[]\n",
    "    for i in range(len(dataset)):\n",
    "        temp = dataset[i].split()\n",
    "        if (len(temp)==2):\n",
    "            data.append(temp)\n",
    "    data_ls.append(pd.DataFrame(data, columns = ['Word', 'Tag']))\n",
    "\n",
    "EN = data_ls[0]\n",
    "AL = data_ls[1]\n",
    "CN = data_ls[2]\n",
    "SG = data_ls[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_ls)):\n",
    "    print(name[i])\n",
    "    print(data_ls[i].head())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_ls)):\n",
    "    print(name[i])\n",
    "    print(data_ls[i]['Tag'].value_counts())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emission(df,word,tag):\n",
    "    is_tag = (df.Tag==tag)\n",
    "    y = is_tag.sum()\n",
    "    xy = (df.Word[is_tag]==word).sum()\n",
    "    return xy/y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(emission(EN,\"are\",\"B-VP\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-91ffd87c575a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mEN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msmoothen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mAL\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msmoothen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mCN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msmoothen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'EN' is not defined"
     ]
    }
   ],
   "source": [
    "def smoothen(df,k):\n",
    "    ls = df['Word'].value_counts()[df['Word'].value_counts()<k].index.tolist()\n",
    "    df.loc[df['Word'].isin(ls), 'Word'] = \"#UNK#\"\n",
    "    return df\n",
    "\n",
    "EN=smoothen(EN,k=3)\n",
    "AL=smoothen(AL,k=3)\n",
    "CN=smoothen(CN,k=3)\n",
    "SG=smoothen(SG,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN\n",
      "         Word     Tag\n",
      "0   Municipal    B-NP\n",
      "1       bonds    I-NP\n",
      "2         are    B-VP\n",
      "3   generally  B-ADVP\n",
      "4           a  B-ADJP\n",
      "5         bit  I-ADJP\n",
      "6       safer  I-ADJP\n",
      "7        than    B-PP\n",
      "8   corporate    B-NP\n",
      "9       bonds    I-NP\n",
      "10         in    B-PP\n",
      "11          a    B-NP\n",
      "12  recession    I-NP\n",
      "13          ,       O\n",
      "14        but       O\n",
      "15        not  B-ADJP\n",
      "16         as  I-ADJP\n",
      "17       safe  I-ADJP\n",
      "18         as    B-PP\n",
      "19      bonds    B-NP\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_ls)):\n",
    "    print(name[i])\n",
    "    print(data_ls[i].head(20))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d163394cfa41e08d382416a74a0ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garyo\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2a3ec997cff1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mEN_count_series\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Word'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Tag'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mAL_count_series\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Word'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Tag'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mCN_count_series\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Word'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Tag'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'EN' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "tqdm_notebook().pandas()\n",
    "\n",
    "\n",
    "EN_count_series = EN.groupby(['Word', 'Tag']).size()\n",
    "AL_count_series = AL.groupby(['Word', 'Tag']).size()\n",
    "CN_count_series = CN.groupby(['Word', 'Tag']).size()\n",
    "SG_count_series = SG.groupby(['Word', 'Tag']).size()\n",
    "\n",
    "EN_tag_count = EN['Tag'].value_counts()\n",
    "AL_tag_count = AL['Tag'].value_counts()\n",
    "CN_tag_count = CN['Tag'].value_counts()\n",
    "SG_tag_count = SG['Tag'].value_counts()\n",
    "\n",
    "EN_count_u = pd.Series(EN_count_series.index.get_level_values('Tag').tolist(), index=EN_count_series.index).progress_apply(lambda x: EN_tag_count[x])\n",
    "AL_count_u = pd.Series(AL_count_series.index.get_level_values('Tag').tolist(), index=AL_count_series.index).progress_apply(lambda x: AL_tag_count[x])\n",
    "CN_count_u = pd.Series(CN_count_series.index.get_level_values('Tag').tolist(), index=CN_count_series.index).progress_apply(lambda x: CN_tag_count[x])\n",
    "SG_count_u = pd.Series(SG_count_series.index.get_level_values('Tag').tolist(), index=SG_count_series.index).progress_apply(lambda x: SG_tag_count[x])\n",
    "\n",
    "EN_count_series = EN_count_series / EN_count_u\n",
    "AL_count_series = AL_count_series / AL_count_u\n",
    "CN_count_series = CN_count_series / CN_count_u\n",
    "SG_count_series = SG_count_series / SG_count_u\n",
    "\n",
    "\n",
    "count_series=[EN_count_series, AL_count_series, CN_count_series, SG_count_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_series' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-152d815b3f6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_series\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_series\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'count_series' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(count_series)):\n",
    "    print(name[i])\n",
    "    print(count_series[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def argmax(df,word):\n",
    "#     if (word==\"\"):\n",
    "#         return \"\"\n",
    "#     tags = (df.Tag[df.Word==word]).value_counts().index.tolist()\n",
    "#     if (len(tags)==0):\n",
    "#         tags = (df.Tag[df.Word==\"#UNK#\"]).value_counts().index.tolist()\n",
    "#     emission_ls=[]\n",
    "#     for i in tags:\n",
    "#         emission_ls.append(emission(df,word,i))\n",
    "#     return(tags[emission_ls.index(max(emission_ls))])\n",
    "\n",
    "def argmax(df,word):\n",
    "    if (word==\"\"):\n",
    "        return \"\"\n",
    "    try:\n",
    "        value = df.loc[word].idxmax()\n",
    "    except:\n",
    "        value = df.loc[\"#UNK#\"].idxmax()\n",
    "    \n",
    "    return (value)\n",
    "\n",
    "# def argmax(df,word):\n",
    "#     if (word==\"\"):\n",
    "#         return \"\"\n",
    "#     tags = pd.DataFrame((df.Tag[df.Word==word]).value_counts().index.tolist(), columns=['Tags'])\n",
    "#     if (len(tags.index)==0):\n",
    "#         tags = pd.DataFrame((df.Tag[df.Word==\"#UNK#\"]).value_counts().index.tolist(), columns=['Tags'])\n",
    "#         word=\"#UNK#\"\n",
    "#     tags['Emission'] = tags['Tags'].apply(lambda x: emission(df,word,x))\n",
    "#     return(tags['Tags'].loc[tags['Emission'].idxmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7ae14499b0401e8147e23a456edd0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27225), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f205393e2d4b919173b744e31b08e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26155), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52801c3b00954bc68ef67ee51f0477e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=24225), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd4833bbbae42a1a16bf599a2d405a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50763), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_ls = []\n",
    "count=0\n",
    "for i in name:\n",
    "    file = \"./\"+i+\"/dev.in\"\n",
    "    file_object = open(file, \"r\")\n",
    "    ls=[]\n",
    "    for line in file_object:\n",
    "        ls.append(line.strip())\n",
    "    df = pd.DataFrame(ls, columns = ['Word'])\n",
    "    df['Tag'] = df['Word'].progress_apply(lambda x: argmax(count_series[count], x))\n",
    "    test_ls.append(df)\n",
    "    count+=1\n",
    "\n",
    "EN_test = test_ls[0]\n",
    "AL_test = test_ls[1]\n",
    "CN_test = test_ls[2]\n",
    "SG_test = test_ls[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN\n",
      "           Word     Tag\n",
      "0           HBO    B-NP\n",
      "1           has    B-VP\n",
      "2         close  B-ADJP\n",
      "3            to    B-PP\n",
      "4            24    I-NP\n",
      "...         ...     ...\n",
      "27220      were    B-VP\n",
      "27221        in    B-PP\n",
      "27222  Congress    B-NP\n",
      "27223         .       O\n",
      "27224                  \n",
      "\n",
      "[27225 rows x 2 columns]\n",
      "\n",
      "\n",
      "AL\n",
      "      Word          Tag\n",
      "0        杭       B-CITY\n",
      "1        州       I-CITY\n",
      "2        市       I-CITY\n",
      "3        西     B-ASSIST\n",
      "4        湖   I-DISTRICT\n",
      "...    ...          ...\n",
      "26150    油     I-SUBPOI\n",
      "26151    站     I-SUBPOI\n",
      "26152    电  B-OTHERINFO\n",
      "26153    联  I-OTHERINFO\n",
      "26154                  \n",
      "\n",
      "[26155 rows x 2 columns]\n",
      "\n",
      "\n",
      "CN\n",
      "      Word         Tag\n",
      "0        一  I-negative\n",
      "1       觉醒  B-negative\n",
      "2       来天  B-negative\n",
      "3        都           O\n",
      "4        黑   B-neutral\n",
      "...    ...         ...\n",
      "24220   甜蜜  B-positive\n",
      "24221    的           O\n",
      "24222   浪漫           O\n",
      "24223    。           O\n",
      "24224                 \n",
      "\n",
      "[24225 rows x 2 columns]\n",
      "\n",
      "\n",
      "SG\n",
      "                          Word         Tag\n",
      "0                         Tour  B-positive\n",
      "1                     Scotland   B-neutral\n",
      "2                    followers           O\n",
      "3                           to           O\n",
      "4                        visit           O\n",
      "...                        ...         ...\n",
      "50758                   trends           O\n",
      "50759                       at           O\n",
      "50760  https://t.co/psP0GzBgZB           O\n",
      "50761                  #trndnl           O\n",
      "50762                                     \n",
      "\n",
      "[50763 rows x 2 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_ls)):\n",
    "    print(name[i])\n",
    "    print(test_ls[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_ls=[]\n",
    "for i in name:\n",
    "    file = \"./\"+i+\"/dev.out\"\n",
    "    file_object = open(file, \"r\")\n",
    "    ls=[]\n",
    "    for line in file_object:\n",
    "        temp=line.split()\n",
    "        if (len(temp)==0):\n",
    "            temp.append(\"\")\n",
    "            temp.append(\"\")\n",
    "        ls.append(temp)\n",
    "    test_out_ls.append(pd.DataFrame(ls, columns = ['Word', 'Tag']))\n",
    "\n",
    "EN_test_out = test_out_ls[0]\n",
    "AL_test_out = test_out_ls[1]\n",
    "CN_test_out = test_out_ls[2]\n",
    "SG_test_out = test_out_ls[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN\n",
      "           Word   Tag\n",
      "0           HBO  B-NP\n",
      "1           has  B-VP\n",
      "2         close  B-NP\n",
      "3            to  I-NP\n",
      "4            24  I-NP\n",
      "...         ...   ...\n",
      "27220      were  B-VP\n",
      "27221        in  B-PP\n",
      "27222  Congress  B-NP\n",
      "27223         .     O\n",
      "27224                \n",
      "\n",
      "[27225 rows x 2 columns]\n",
      "\n",
      "\n",
      "AL\n",
      "      Word          Tag\n",
      "0        杭       B-CITY\n",
      "1        州       I-CITY\n",
      "2        市       I-CITY\n",
      "3        西   B-DISTRICT\n",
      "4        湖   I-DISTRICT\n",
      "...    ...          ...\n",
      "26150    油        I-POI\n",
      "26151    站        I-POI\n",
      "26152    电  B-REDUNDANT\n",
      "26153    联  I-REDUNDANT\n",
      "26154                  \n",
      "\n",
      "[26155 rows x 2 columns]\n",
      "\n",
      "\n",
      "CN\n",
      "      Word Tag\n",
      "0        一   O\n",
      "1       觉醒   O\n",
      "2       来天   O\n",
      "3        都   O\n",
      "4        黑   O\n",
      "...    ...  ..\n",
      "24220   甜蜜   O\n",
      "24221    的   O\n",
      "24222   浪漫   O\n",
      "24223    。   O\n",
      "24224         \n",
      "\n",
      "[24225 rows x 2 columns]\n",
      "\n",
      "\n",
      "SG\n",
      "                          Word        Tag\n",
      "0                         Tour  B-neutral\n",
      "1                     Scotland  I-neutral\n",
      "2                    followers          O\n",
      "3                           to          O\n",
      "4                        visit          O\n",
      "...                        ...        ...\n",
      "50758                   trends          O\n",
      "50759                       at          O\n",
      "50760  https://t.co/psP0GzBgZB          O\n",
      "50761                  #trndnl          O\n",
      "50762                                    \n",
      "\n",
      "[50763 rows x 2 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_out_ls)):\n",
    "    print(name[i])\n",
    "    print(test_out_ls[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(name)):\n",
    "    file = \"./\"+name[i]+\"/dev.prediction\"\n",
    "    test_ls[i].to_csv(file, sep=\" \", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#Entity in gold data: 13179\r\n",
      "#Entity in prediction: 19406\r\n",
      "\r\n",
      "#Correct Entity : 9152\r\n",
      "Entity  precision: 0.4716\r\n",
      "Entity  recall: 0.6944\r\n",
      "Entity  F: 0.5617\r\n",
      "\r\n",
      "#Correct Sentiment : 7644\r\n",
      "Sentiment  precision: 0.3939\r\n",
      "Sentiment  recall: 0.5800\r\n",
      "Sentiment  F: 0.4692\r\n"
     ]
    }
   ],
   "source": [
    "!python3 ./EvalScript/evalResult.py ./EN/dev.out ./EN/dev.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#Entity in gold data: 8408\r\n",
      "#Entity in prediction: 19484\r\n",
      "\r\n",
      "#Correct Entity : 2898\r\n",
      "Entity  precision: 0.1487\r\n",
      "Entity  recall: 0.3447\r\n",
      "Entity  F: 0.2078\r\n",
      "\r\n",
      "#Correct Sentiment : 2457\r\n",
      "Sentiment  precision: 0.1261\r\n",
      "Sentiment  recall: 0.2922\r\n",
      "Sentiment  F: 0.1762\r\n"
     ]
    }
   ],
   "source": [
    "!python3 ./EvalScript/evalResult.py ./AL/dev.out ./AL/dev.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#Entity in gold data: 1478\r\n",
      "#Entity in prediction: 9373\r\n",
      "\r\n",
      "#Correct Entity : 765\r\n",
      "Entity  precision: 0.0816\r\n",
      "Entity  recall: 0.5176\r\n",
      "Entity  F: 0.1410\r\n",
      "\r\n",
      "#Correct Sentiment : 285\r\n",
      "Sentiment  precision: 0.0304\r\n",
      "Sentiment  recall: 0.1928\r\n",
      "Sentiment  F: 0.0525\r\n"
     ]
    }
   ],
   "source": [
    "!python3 ./EvalScript/evalResult.py ./CN/dev.out ./CN/dev.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "#Entity in gold data: 4537\r\n",
      "#Entity in prediction: 18451\r\n",
      "\r\n",
      "#Correct Entity : 2632\r\n",
      "Entity  precision: 0.1426\r\n",
      "Entity  recall: 0.5801\r\n",
      "Entity  F: 0.2290\r\n",
      "\r\n",
      "#Correct Sentiment : 1239\r\n",
      "Sentiment  precision: 0.0672\r\n",
      "Sentiment  recall: 0.2731\r\n",
      "Sentiment  F: 0.1078\r\n"
     ]
    }
   ],
   "source": [
    "!python3 ./EvalScript/evalResult.py ./SG/dev.out ./SG/dev.prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
